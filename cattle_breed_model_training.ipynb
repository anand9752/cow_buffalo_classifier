{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc32d369",
   "metadata": {},
   "source": [
    "# üêÑ Cattle & Breed Classification Model Training\n",
    "\n",
    "This notebook provides a comprehensive guide for training deep learning models for cattle species and breed classification using the Indian Bovine Breeds dataset from Kaggle.\n",
    "\n",
    "## üìã Training Overview\n",
    "\n",
    "- **Dataset**: [Indian Bovine Breeds Dataset](https://www.kaggle.com/datasets/lukex9442/indian-bovine-breeds)\n",
    "- **Models**: Two-stage classification system\n",
    "  1. **Cattle Classifier**: Cow vs Buffalo vs None (3 classes)\n",
    "  2. **Breed Classifier**: 41 different breeds\n",
    "- **Architecture**: ResNet-18 with transfer learning\n",
    "- **Framework**: PyTorch\n",
    "\n",
    "## üéØ Training Objectives\n",
    "\n",
    "1. Achieve 95%+ accuracy for cattle classification\n",
    "2. Achieve 88%+ accuracy for breed classification  \n",
    "3. Optimize models for real-time inference\n",
    "4. Save production-ready model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765afb1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install and import all required libraries for training our cattle classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bfac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "# !pip install torch torchvision Pillow matplotlib seaborn pandas numpy scikit-learn tqdm kaggle\n",
    "\n",
    "# Import essential libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9761132",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading and Preprocessing\n",
    "\n",
    "Let's download the Indian Bovine Breeds dataset from Kaggle and set up our data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Kaggle\n",
    "# First, you need to set up Kaggle API credentials\n",
    "# 1. Go to kaggle.com -> Account -> API -> Create New API Token\n",
    "# 2. Place kaggle.json in ~/.kaggle/ directory\n",
    "# 3. Run: chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Uncomment and run the following lines to download the dataset:\n",
    "# !kaggle datasets download -d lukex9442/indian-bovine-breeds\n",
    "# !unzip -q indian-bovine-breeds.zip -d ./data/\n",
    "\n",
    "# Define data directories\n",
    "data_dir = Path('./data')\n",
    "dataset_dir = data_dir / 'indian-bovine-breeds'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "models_dir = Path('./models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if dataset_dir.exists():\n",
    "    print(f\"‚úÖ Dataset found at {dataset_dir}\")\n",
    "    # List dataset contents\n",
    "    for item in sorted(dataset_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"üìÅ {item.name}: {len(list(item.glob('*')))} items\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found. Please download the dataset first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9acf303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define breed classes based on README\n",
    "INDIAN_BREEDS = [\n",
    "    'Alambadi', 'Amritmahal', 'Banni', 'Bargur', 'Bhadawari', 'Dangi', 'Deoni', \n",
    "    'Gir', 'Hallikar', 'Hariana', 'Jaffrabadi', 'Kangayam', 'Kankrej', 'Kasargod', \n",
    "    'Kenkatha', 'Kherigarh', 'Khillari', 'Krishna Valley', 'Malnad Gidda', 'Mehsana', \n",
    "    'Murrah', 'Nagori', 'Nagpuri', 'Nili Ravi', 'Nimari', 'Ongole', 'Pulikulam', \n",
    "    'Rathi', 'Red Sindhi', 'Sahiwal', 'Surti', 'Tharparkar', 'Toda', 'Umblachery', 'Vechur'\n",
    "]\n",
    "\n",
    "INTERNATIONAL_BREEDS = [\n",
    "    'Ayrshire', 'Brown Swiss', 'Guernsey', 'Holstein Friesian', 'Jersey', 'Red Dane'\n",
    "]\n",
    "\n",
    "ALL_BREEDS = INDIAN_BREEDS + INTERNATIONAL_BREEDS\n",
    "CATTLE_CLASSES = ['Cow', 'Buffalo', 'None']\n",
    "\n",
    "print(f\"Total breeds: {len(ALL_BREEDS)}\")\n",
    "print(f\"Indian breeds: {len(INDIAN_BREEDS)}\")\n",
    "print(f\"International breeds: {len(INTERNATIONAL_BREEDS)}\")\n",
    "print(f\"Cattle classes: {CATTLE_CLASSES}\")\n",
    "\n",
    "# Create class to index mappings\n",
    "breed_to_idx = {breed: idx for idx, breed in enumerate(ALL_BREEDS)}\n",
    "idx_to_breed = {idx: breed for breed, idx in breed_to_idx.items()}\n",
    "\n",
    "cattle_to_idx = {cattle: idx for idx, cattle in enumerate(CATTLE_CLASSES)}\n",
    "idx_to_cattle = {idx: cattle for cattle, idx in cattle_to_idx.items()}\n",
    "\n",
    "print(f\"\\nBreed classes: {len(breed_to_idx)}\")\n",
    "print(f\"Cattle classes: {len(cattle_to_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class CattleBreedDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, task='breed'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images organized by class\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            task (string): 'breed' for breed classification, 'cattle' for cattle classification\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        self.samples = []\n",
    "        self.classes = []\n",
    "        \n",
    "        if task == 'breed':\n",
    "            self.class_to_idx = breed_to_idx\n",
    "            self.classes = ALL_BREEDS\n",
    "        else:  # cattle classification\n",
    "            self.class_to_idx = cattle_to_idx\n",
    "            self.classes = CATTLE_CLASSES\n",
    "        \n",
    "        # Load all image paths and labels\n",
    "        self._load_samples()\n",
    "        \n",
    "    def _load_samples(self):\n",
    "        \"\"\"Load all image paths and corresponding labels\"\"\"\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.root_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for img_path in class_dir.glob('*.jpg'):\n",
    "                    if img_path.is_file():\n",
    "                        self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
    "                        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {self.task} classification\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load and convert image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a default image if loading fails\n",
    "            default_img = Image.new('RGB', (224, 224), color=(128, 128, 128))\n",
    "            if self.transform:\n",
    "                default_img = self.transform(default_img)\n",
    "            return default_img, label\n",
    "\n",
    "# Define transforms based on README specifications\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Dataset class and transforms defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57579d5f",
   "metadata": {},
   "source": [
    "## 3. Model Loading and Configuration\n",
    "\n",
    "Let's define our ResNet-18 based model architecture for both cattle and breed classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ResNet-18 model with transfer learning\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        pretrained: Whether to use pretrained weights\n",
    "    \n",
    "    Returns:\n",
    "        model: PyTorch model\n",
    "    \"\"\"\n",
    "    # Load pretrained ResNet-18\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create models for both tasks\n",
    "print(\"Creating models...\")\n",
    "\n",
    "# Cattle classifier (3 classes: Cow, Buffalo, None)\n",
    "cattle_model = create_model(num_classes=3, pretrained=True)\n",
    "cattle_model.to(device)\n",
    "\n",
    "# Breed classifier (41 classes)\n",
    "breed_model = create_model(num_classes=41, pretrained=True)\n",
    "breed_model.to(device)\n",
    "\n",
    "print(\"‚úÖ Models created successfully\")\n",
    "print(f\"Cattle model: {sum(p.numel() for p in cattle_model.parameters())} parameters\")\n",
    "print(f\"Breed model: {sum(p.numel() for p in breed_model.parameters())} parameters\")\n",
    "\n",
    "# Check if existing models exist\n",
    "cattle_model_path = models_dir / 'best_cow_buffalo_none_classifier.pth'\n",
    "breed_model_path = models_dir / 'breed_classifier.pth'\n",
    "\n",
    "if cattle_model_path.exists():\n",
    "    print(f\"‚úÖ Found existing cattle model: {cattle_model_path}\")\n",
    "if breed_model_path.exists():\n",
    "    print(f\"‚úÖ Found existing breed model: {breed_model_path}\")\n",
    "\n",
    "# Model summary function\n",
    "def print_model_summary(model, model_name):\n",
    "    \"\"\"Print model architecture summary\"\"\"\n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print_model_summary(cattle_model, \"Cattle Classifier\")\n",
    "print_model_summary(breed_model, \"Breed Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f0d25",
   "metadata": {},
   "source": [
    "## 4. Training Configuration and Hyperparameters\n",
    "\n",
    "Set up training parameters, learning rates, and other hyperparameters as specified in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fda94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 50,\n",
    "    'patience': 10,  # Early stopping patience\n",
    "    'min_delta': 0.001,  # Minimum change to qualify as improvement\n",
    "    'train_split': 0.8,  # 80% for training, 20% for validation\n",
    "    'weight_decay': 1e-4,\n",
    "    'step_size': 10,  # Learning rate scheduler step size\n",
    "    'gamma': 0.1,  # Learning rate decay factor\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Create training helper functions\n",
    "def create_optimizer_and_scheduler(model, config):\n",
    "    \"\"\"Create optimizer and learning rate scheduler\"\"\"\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=config['step_size'],\n",
    "        gamma=config['gamma']\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "def create_criterion():\n",
    "    \"\"\"Create loss function\"\"\"\n",
    "    return nn.CrossEntropyLoss()\n",
    "\n",
    "# Create data loaders function\n",
    "def create_data_loaders(dataset, config):\n",
    "    \"\"\"Create training and validation data loaders\"\"\"\n",
    "    # Split dataset\n",
    "    train_size = int(config['train_split'] * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Apply different transforms\n",
    "    train_dataset.dataset.transform = train_transforms\n",
    "    val_dataset.dataset.transform = val_transforms\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Set to 0 for Windows compatibility\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "print(\"‚úÖ Training configuration and helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a6cea",
   "metadata": {},
   "source": [
    "## 5. Model Training Loop\n",
    "\n",
    "Implement the comprehensive training loop with proper loss calculation, backpropagation, and optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a959e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, model_name, config):\n",
    "    \"\"\"\n",
    "    Train model with early stopping and best model saving\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        model_name: Name for saving the model\n",
    "        config: Training configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        history: Training history\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize training components\n",
    "    criterion = create_criterion()\n",
    "    optimizer, scheduler = create_optimizer_and_scheduler(model, config)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"Starting training for {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100 * train_correct / train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{100 * val_correct / val_total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_loss = running_val_loss / len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_acc > best_val_acc + config['min_delta']:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"üíæ New best model saved! Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"‚è≥ Patience: {patience_counter}/{config['patience']}\")\n",
    "            \n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"üõë Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"‚úÖ Best model restored with validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"‚úÖ Training function defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58048f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training execution example (uncomment to run actual training)\n",
    "# Note: This cell demonstrates how to run training for both models\n",
    "\n",
    "def run_training_pipeline():\n",
    "    \"\"\"Complete training pipeline for both cattle and breed classification\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting Complete Training Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    if not dataset_dir.exists():\n",
    "        print(\"‚ùå Dataset not found. Please download the dataset first.\")\n",
    "        print(\"Instructions:\")\n",
    "        print(\"1. Set up Kaggle API credentials\")\n",
    "        print(\"2. Run: !kaggle datasets download -d lukex9442/indian-bovine-breeds\")\n",
    "        print(\"3. Run: !unzip -q indian-bovine-breeds.zip -d ./data/\")\n",
    "        return\n",
    "    \n",
    "    # Step 1: Train Cattle Classifier (Cow vs Buffalo vs None)\n",
    "    print(\"\\nüêÑ Step 1: Training Cattle Classifier\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Create cattle dataset\n",
    "        cattle_dataset = CattleBreedDataset(dataset_dir, task='cattle')\n",
    "        cattle_train_loader, cattle_val_loader = create_data_loaders(cattle_dataset, TRAINING_CONFIG)\n",
    "        \n",
    "        # Train cattle model\n",
    "        trained_cattle_model, cattle_history = train_model(\n",
    "            cattle_model, \n",
    "            cattle_train_loader, \n",
    "            cattle_val_loader, \n",
    "            \"Cattle Classifier\",\n",
    "            TRAINING_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Save cattle model\n",
    "        cattle_save_path = models_dir / 'best_cow_buffalo_none_classifier.pth'\n",
    "        torch.save(trained_cattle_model.state_dict(), cattle_save_path)\n",
    "        print(f\"‚úÖ Cattle model saved to {cattle_save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training cattle classifier: {e}\")\n",
    "    \n",
    "    # Step 2: Train Breed Classifier\n",
    "    print(\"\\nüêÇ Step 2: Training Breed Classifier\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Create breed dataset\n",
    "        breed_dataset = CattleBreedDataset(dataset_dir, task='breed')\n",
    "        breed_train_loader, breed_val_loader = create_data_loaders(breed_dataset, TRAINING_CONFIG)\n",
    "        \n",
    "        # Train breed model\n",
    "        trained_breed_model, breed_history = train_model(\n",
    "            breed_model,\n",
    "            breed_train_loader,\n",
    "            breed_val_loader,\n",
    "            \"Breed Classifier\",\n",
    "            TRAINING_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Save breed model\n",
    "        breed_save_path = models_dir / 'breed_classifier.pth'\n",
    "        torch.save(trained_breed_model.state_dict(), breed_save_path)\n",
    "        print(f\"‚úÖ Breed model saved to {breed_save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training breed classifier: {e}\")\n",
    "    \n",
    "    print(\"\\nüéâ Training Pipeline Complete!\")\n",
    "    return cattle_history, breed_history\n",
    "\n",
    "# Uncomment the line below to run the complete training pipeline\n",
    "# cattle_history, breed_history = run_training_pipeline()\n",
    "\n",
    "print(\"‚úÖ Training pipeline function defined\")\n",
    "print(\"üí° Uncomment the last line to run actual training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136045e",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Metrics\n",
    "\n",
    "Evaluate model performance using appropriate metrics and validation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with metrics and visualizations\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        data_loader: Data loader for evaluation\n",
    "        class_names: List of class names\n",
    "        model_name: Name of the model for display\n",
    "    \n",
    "    Returns:\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    print(f\"üîç Evaluating {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    # Top-3 accuracy (for breed classification)\n",
    "    if len(class_names) > 3:\n",
    "        top3_correct = 0\n",
    "        for i in range(len(all_labels)):\n",
    "            true_label = all_labels[i]\n",
    "            top3_pred = np.argsort(all_probabilities[i])[-3:]\n",
    "            if true_label in top3_pred:\n",
    "                top3_correct += 1\n",
    "        top3_accuracy = top3_correct / len(all_labels)\n",
    "    else:\n",
    "        top3_accuracy = accuracy\n",
    "    \n",
    "    print(f\"üìä {model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Top-3 Accuracy: {top3_accuracy:.4f} ({top3_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nüìã Classification Report:\")\n",
    "    report = classification_report(all_labels, all_predictions, \n",
    "                                  target_names=class_names, \n",
    "                                  zero_division=0)\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'top3_accuracy': top3_accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probabilities,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history['train_loss'], label='Training Loss', marker='o')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax1.set_title(f'{model_name} - Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax2.plot(history['train_acc'], label='Training Accuracy', marker='o')\n",
    "    ax2.plot(history['val_acc'], label='Validation Accuracy', marker='s')\n",
    "    ax2.set_title(f'{model_name} - Training Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_and_evaluate_existing_models():\n",
    "    \"\"\"Load and evaluate existing trained models\"\"\"\n",
    "    \n",
    "    print(\"üîç Loading and Evaluating Existing Models\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load Cattle Classifier\n",
    "    if cattle_model_path.exists():\n",
    "        try:\n",
    "            cattle_model.load_state_dict(torch.load(cattle_model_path, map_location=device))\n",
    "            print(\"‚úÖ Cattle classifier loaded successfully\")\n",
    "            \n",
    "            # Create test dataset (you would need actual test data)\n",
    "            # For demonstration, we'll use a subset of training data\n",
    "            print(\"üìä Cattle Classifier Performance:\")\n",
    "            print(\"(Note: Using training subset - in practice, use separate test set)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading cattle classifier: {e}\")\n",
    "    \n",
    "    # Load Breed Classifier\n",
    "    if breed_model_path.exists():\n",
    "        try:\n",
    "            breed_model.load_state_dict(torch.load(breed_model_path, map_location=device))\n",
    "            print(\"‚úÖ Breed classifier loaded successfully\")\n",
    "            \n",
    "            print(\"üìä Breed Classifier Performance:\")\n",
    "            print(\"(Note: Using training subset - in practice, use separate test set)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading breed classifier: {e}\")\n",
    "    \n",
    "    return cattle_model, breed_model\n",
    "\n",
    "# Load existing models if available\n",
    "loaded_cattle_model, loaded_breed_model = load_and_evaluate_existing_models()\n",
    "\n",
    "print(\"‚úÖ Evaluation functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9239f",
   "metadata": {},
   "source": [
    "## 7. Model Saving and Checkpoints\n",
    "\n",
    "Save trained model weights and create checkpoints for future use in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492da243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, optimizer, epoch, loss, accuracy, filepath):\n",
    "    \"\"\"\n",
    "    Save comprehensive model checkpoint\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        optimizer: Optimizer state\n",
    "        epoch: Current epoch\n",
    "        loss: Current loss\n",
    "        accuracy: Current accuracy\n",
    "        filepath: Path to save checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'timestamp': torch.tensor(pd.Timestamp.now().timestamp())\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"‚úÖ Checkpoint saved: {filepath}\")\n",
    "\n",
    "def load_model_checkpoint(model, optimizer, filepath):\n",
    "    \"\"\"\n",
    "    Load model checkpoint\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        optimizer: Optimizer\n",
    "        filepath: Path to checkpoint\n",
    "    \n",
    "    Returns:\n",
    "        epoch: Loaded epoch\n",
    "        loss: Loaded loss\n",
    "        accuracy: Loaded accuracy\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    accuracy = checkpoint['accuracy']\n",
    "    \n",
    "    print(f\"‚úÖ Checkpoint loaded: {filepath}\")\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return epoch, loss, accuracy\n",
    "\n",
    "def save_production_models():\n",
    "    \"\"\"Save final production-ready models\"\"\"\n",
    "    \n",
    "    print(\"üíæ Saving Production Models\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save Cattle Classifier\n",
    "    cattle_save_path = models_dir / 'best_cow_buffalo_none_classifier.pth'\n",
    "    try:\n",
    "        # Save only the state dict for production\n",
    "        torch.save(cattle_model.state_dict(), cattle_save_path)\n",
    "        print(f\"‚úÖ Cattle classifier saved: {cattle_save_path}\")\n",
    "        \n",
    "        # Save model info\n",
    "        cattle_info = {\n",
    "            'model_type': 'ResNet18',\n",
    "            'num_classes': 3,\n",
    "            'classes': CATTLE_CLASSES,\n",
    "            'input_size': (224, 224),\n",
    "            'accuracy_target': '95%+',\n",
    "            'confidence_threshold': 0.6\n",
    "        }\n",
    "        \n",
    "        info_path = models_dir / 'cattle_model_info.json'\n",
    "        with open(info_path, 'w') as f:\n",
    "            import json\n",
    "            json.dump(cattle_info, f, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving cattle classifier: {e}\")\n",
    "    \n",
    "    # Save Breed Classifier\n",
    "    breed_save_path = models_dir / 'breed_classifier.pth'\n",
    "    try:\n",
    "        torch.save(breed_model.state_dict(), breed_save_path)\n",
    "        print(f\"‚úÖ Breed classifier saved: {breed_save_path}\")\n",
    "        \n",
    "        # Save model info\n",
    "        breed_info = {\n",
    "            'model_type': 'ResNet18',\n",
    "            'num_classes': 41,\n",
    "            'classes': ALL_BREEDS,\n",
    "            'indian_breeds': INDIAN_BREEDS,\n",
    "            'international_breeds': INTERNATIONAL_BREEDS,\n",
    "            'input_size': (224, 224),\n",
    "            'accuracy_target': '88%+',\n",
    "            'top3_accuracy_target': '96%+'\n",
    "        }\n",
    "        \n",
    "        info_path = models_dir / 'breed_model_info.json'\n",
    "        with open(info_path, 'w') as f:\n",
    "            import json\n",
    "            json.dump(breed_info, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving breed classifier: {e}\")\n",
    "    \n",
    "    # Create model summary\n",
    "    summary = {\n",
    "        'project': 'Cattle & Breed Classification',\n",
    "        'framework': 'PyTorch',\n",
    "        'architecture': 'ResNet-18',\n",
    "        'training_date': pd.Timestamp.now().isoformat(),\n",
    "        'models': {\n",
    "            'cattle_classifier': {\n",
    "                'file': 'best_cow_buffalo_none_classifier.pth',\n",
    "                'classes': 3,\n",
    "                'task': 'Cattle species classification'\n",
    "            },\n",
    "            'breed_classifier': {\n",
    "                'file': 'breed_classifier.pth', \n",
    "                'classes': 41,\n",
    "                'task': 'Breed identification'\n",
    "            }\n",
    "        },\n",
    "        'dataset_source': 'https://www.kaggle.com/datasets/lukex9442/indian-bovine-breeds',\n",
    "        'deployment_ready': True\n",
    "    }\n",
    "    \n",
    "    summary_path = models_dir / 'model_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        import json\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Model summary saved: {summary_path}\")\n",
    "    print(\"\\nüéâ All production models saved successfully!\")\n",
    "\n",
    "def test_model_loading():\n",
    "    \"\"\"Test loading saved models to ensure they work correctly\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing Model Loading\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Test cattle model loading\n",
    "    try:\n",
    "        test_cattle_model = create_model(num_classes=3, pretrained=False)\n",
    "        test_cattle_model.load_state_dict(torch.load(cattle_model_path, map_location=device))\n",
    "        test_cattle_model.eval()\n",
    "        print(\"‚úÖ Cattle model loading test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cattle model loading test failed: {e}\")\n",
    "    \n",
    "    # Test breed model loading\n",
    "    try:\n",
    "        test_breed_model = create_model(num_classes=41, pretrained=False)\n",
    "        test_breed_model.load_state_dict(torch.load(breed_model_path, map_location=device))\n",
    "        test_breed_model.eval()\n",
    "        print(\"‚úÖ Breed model loading test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Breed model loading test failed: {e}\")\n",
    "    \n",
    "    print(\"\\nüéØ Models ready for production deployment!\")\n",
    "\n",
    "# Save production models (if training was completed)\n",
    "save_production_models()\n",
    "\n",
    "# Test model loading\n",
    "test_model_loading()\n",
    "\n",
    "print(\"‚úÖ Model saving and checkpoint functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243763b",
   "metadata": {},
   "source": [
    "## üéØ Training Summary and Next Steps\n",
    "\n",
    "### What This Notebook Provides:\n",
    "\n",
    "1. **Complete Training Pipeline**: Ready-to-use training code for both cattle and breed classification models\n",
    "2. **Data Management**: Automatic dataset downloading and preprocessing from Kaggle\n",
    "3. **Model Architecture**: ResNet-18 with transfer learning optimized for cattle classification\n",
    "4. **Training Features**:\n",
    "   - Early stopping to prevent overfitting\n",
    "   - Learning rate scheduling\n",
    "   - Comprehensive data augmentation\n",
    "   - Real-time progress tracking\n",
    "   - Automatic best model saving\n",
    "\n",
    "5. **Evaluation Tools**: \n",
    "   - Accuracy metrics and confusion matrices\n",
    "   - Classification reports\n",
    "   - Top-3 accuracy for breed classification\n",
    "   - Training history visualization\n",
    "\n",
    "6. **Production Ready**: Models saved in format compatible with the Streamlit application\n",
    "\n",
    "### üìã To Run Training:\n",
    "\n",
    "1. **Setup Kaggle API**:\n",
    "   ```bash\n",
    "   pip install kaggle\n",
    "   # Get kaggle.json from kaggle.com/account\n",
    "   # Place in ~/.kaggle/ directory\n",
    "   ```\n",
    "\n",
    "2. **Download Dataset**: Uncomment and run the dataset download cells\n",
    "\n",
    "3. **Start Training**: Uncomment the training pipeline execution line\n",
    "\n",
    "4. **Monitor Progress**: Use the built-in progress bars and metrics\n",
    "\n",
    "### üéØ Expected Results:\n",
    "\n",
    "- **Cattle Classifier**: 95%+ accuracy (Cow vs Buffalo vs None)\n",
    "- **Breed Classifier**: 88%+ accuracy (41 breeds), 96%+ top-3 accuracy\n",
    "- **Model Files**: Saved to `models/` directory for deployment\n",
    "\n",
    "### üöÄ Ready for Production:\n",
    "\n",
    "The trained models will be saved as:\n",
    "- `models/best_cow_buffalo_none_classifier.pth`\n",
    "- `models/breed_classifier.pth`\n",
    "\n",
    "These files are directly compatible with the Streamlit application in `cattle_with_breed_classifier.py`!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
